{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "\n",
    "# Decision tree specific modules\n",
    "from sklearn import tree\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer #Can use tfidffvectorizer as well\n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.join(os.getcwd(), os.pardir)\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_npz(os.path.join(DATA_PATH, 'training_feats.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_npz(os.path.join(DATA_PATH, 'test_feats.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49308, 35522)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 35522)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(os.path.join(BASE_PATH, '01-milestone1', 'imputed_train.json'))\n",
    "test_df =  pd.read_json(os.path.join(DATA_PATH, 'test.json.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indexes = test_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "As described in milestone 1, we will do some feature extraction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We first instantiate a decision tree model and train it naively using all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels from {low, medium high} -> {0, 1, 2}\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "We need to split the training data into a training set and a validation set (to evaluate the performance of the model).\n",
    "\n",
    "For now we do 5-fold cross_validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 36201431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial approach is to use all features for training. For the parameters, we simply use the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score:\n",
      "11.1711\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "scores = cross_validate(model, X_train, y_train, scoring='neg_log_loss', cv=5)\n",
    "# Convert negative log loss to log loss\n",
    "test_scores = -1 * scores['test_score']\n",
    "print(\"Log loss score:\")\n",
    "print(test_scores.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try training on the entire train set. We will obtain a model, train it on the test dataset, then submit to kaggle for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['high', 'low', 'medium'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the order is not correct (low corresponds to the label 1, but in the csv they expect the low to be the third column), we must swap columns for y_pred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be a \"bug\" below, I don't think I actually swapped the columns yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_csv(y_pred, X_test_indexes):\n",
    "    df = pd.DataFrame(y_pred, columns=le.classes_)\n",
    "    df.index = X_test_indexes\n",
    "    df.index.name = 'listing_id'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = create_submission_csv(y_pred, X_test_indexes)\n",
    "output.to_csv('decision_tree_predictions_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score from Kaggle\n",
    "9.18820 <- ignore, this is the old score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2\n",
    "\n",
    "It seems that using all the features is not very good. Let's use a smaller set of features.\n",
    "We can choose the top x features in order of descending mutual information (wrt the label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 35520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = mutual_info_classif(X_train, y_train, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean log loss test  score using top 50 features: 11.9486\n",
      "Mean log loss train score using top 50 features: 0.0013\n"
     ]
    }
   ],
   "source": [
    "n_feat = 50\n",
    "top_features = mutual_info.argsort()[-1 * n_feat:][::-1]\n",
    "\n",
    "# Only use these top n features when training, to eliminate overfitting.\n",
    "X_train_final = X_train[:,top_features]\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "scores = cross_validate(model, X_train_final, y_train, scoring='neg_log_loss', cv=5, return_train_score=True)\n",
    "# Convert negative log loss to log loss\n",
    "test_scores = -1 * scores['test_score']\n",
    "train_scores = -1 * scores['train_score']\n",
    "score = test_scores.mean().round(4)\n",
    "train_score = train_scores.mean().round(4)\n",
    "print(\"Mean log loss test  score using top {0} features: {1}\".format(n_feat, score))\n",
    "print(\"Mean log loss train score using top {0} features: {1}\".format(n_feat, train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering top 10 features.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'train_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-20ab9dc0247b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Convert negative log loss to log loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtrain_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'train_score'"
     ]
    }
   ],
   "source": [
    "best_score = 9999999999999999\n",
    "best_n = 0\n",
    "\n",
    "for n_feat in n_feats:\n",
    "    print(\"Considering top {0} features.\".format(n_feat))\n",
    "    top_features = mutual_info.argsort()[-1 * n_feat:][::-1]\n",
    "\n",
    "    # Only use these top n features when training, to eliminate overfitting.\n",
    "    X_train_final = X_train[:,top_features]\n",
    "    \n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    scores = cross_validate(model, X_train_final, y_train, scoring='neg_log_loss', cv=5)\n",
    "    # Convert negative log loss to log loss\n",
    "    test_scores = -1 * scores['test_score']\n",
    "    train_scores = -1 * scores['train_score']\n",
    "\n",
    "    score = test_scores.mean().round(4)\n",
    "    print(\"Mean log loss score using top {0} features: {1}\".format(n_feat, score))\n",
    "    print(\"Mean log loss train score using top {0} features: {1}\".format(n_feat, train_score))\n",
    "    \n",
    "    \n",
    "    cross_val_scores[n_feat] = score\n",
    "    \n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_n = n_feat\n",
    "\n",
    "print(\"The best number of features is {0}\".format(best_n))\n",
    "print(\"The log loss for this number of features is {0}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on entire dataset\n",
    "X_train_final = X_test[:,best_n]\n",
    "X_test_final = X_test[:,best_n]\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test_final)\n",
    "\n",
    "output = create_submission_csv( y_pred, X_test_indexes)\n",
    "output.to_csv('decision_tree_predictions_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3\n",
    "Clearly something is wrong with using the 35,000+ features, which includes the following:\n",
    "* Description word counts\n",
    "* Feature word counts\n",
    "* One hot encodings for building id, manager id\n",
    "* Year, month, day, etc.\n",
    "\n",
    "One thing we can try is reduce the number of features to choose from. We can try excluding the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, min_feats=5):\n",
    "    bathrooms = train_df['bathrooms']\n",
    "    bedrooms = train_df['bedrooms']\n",
    "#     building_ids = train_df['building_id']\n",
    "    latitudes = train_df['latitude']\n",
    "    longitudes = train_df['longitude']\n",
    "#     manager_ids = train_df['manager_id']\n",
    "    prices = train_df['price']\n",
    "    \n",
    "    datetime = pd.to_datetime(train_df['created'])\n",
    "    \n",
    "    months = datetime.dt.month\n",
    "    days = datetime.dt.day\n",
    "    hours = datetime.dt.hour\n",
    "    \n",
    "    # Where Monday = 0, and Sunday = 6\n",
    "    weekdays = datetime.dt.dayofweek\n",
    "    \n",
    "    num_photos = train_df['photos'].str.len()\n",
    "    \n",
    "    # The final dataframe to be returned\n",
    "    final_train_df = pd.DataFrame()\n",
    "    \n",
    "    final_train_df['bathrooms'] = bathrooms\n",
    "    final_train_df['bedrooms'] = bedrooms\n",
    "#     final_train_df['building_ids'] = building_ids \n",
    "    final_train_df['latitudes'] = latitudes\n",
    "    final_train_df['longitudes'] = longitudes\n",
    "#     final_train_df['manager_ids'] = manager_ids\n",
    "    final_train_df['prices'] = prices\n",
    "    \n",
    "    final_train_df['months'] = months\n",
    "    final_train_df['days'] = days\n",
    "    final_train_df['hours'] = hours\n",
    "    \n",
    "    final_train_df['weekdays'] = weekdays\n",
    "    final_train_df['num_photos'] = num_photos\n",
    "    final_train_df.index = train_df['listing_id']\n",
    "\n",
    "    return final_train_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = train_df.drop(columns=['interest_level'])\n",
    "X_test2 = test_df\n",
    "X_train2 = preprocess(X_train2)\n",
    "X_test2 = preprocess(X_test2)\n",
    "drop_cols = ['num_photos', 'months', 'days', 'hours', 'weekdays']\n",
    "X_train2 = X_train2.drop(columns=drop_cols)\n",
    "X_test2 = X_test2.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features is rather small, but at least it is clean. Let's try cross-validation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean log loss test  score: 10.9044\n",
      "Mean log loss train score: 0.073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "scores = cross_validate(model, X_train2, y_train, scoring='neg_log_loss', cv=5, return_train_score=True)\n",
    "# Convert negative log loss to log loss\n",
    "test_scores = -1 * scores['test_score']\n",
    "train_scores = -1 * scores['train_score']\n",
    "score = test_scores.mean().round(4)\n",
    "train_score = train_scores.mean().round(4)\n",
    "print(\"Mean log loss test  score: {0}\".format(score))\n",
    "print(\"Mean log loss train score: {0}\".format( train_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 4\n",
    "\n",
    "If reducing the number of features is not working out, then we should find other ways to reduce overfitting. Pruning is known to be a well-known method for doing so.\n",
    "\n",
    "- entropy for information gain\n",
    "- limiting max_depth to like 30 or so\n",
    "- class_weight = balanced\n",
    "- ccp_alpha = ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean log loss test  score using top 5000 features: 11.7059\n",
      "Mean log loss train score using top 5000 features: 0.001\n"
     ]
    }
   ],
   "source": [
    "# n_feat = 5000\n",
    "# top_features = mutual_info.argsort()[-1 * n_feat:][::-1]\n",
    "\n",
    "# # Only use these top n features when training, to eliminate overfitting.\n",
    "# X_train_final = X_train[:,top_features]\n",
    "\n",
    "# model = tree.DecisionTreeClassifier(criterion='gini', max_depth=n_features/2, class_weight='balanced')\n",
    "\n",
    "# scores = cross_validate(model, X_train_final, y_train, scoring='neg_log_loss', cv=5, return_train_score=True)\n",
    "# # Convert negative log loss to log loss\n",
    "# test_scores = -1 * scores['test_score']\n",
    "# train_scores = -1 * scores['train_score']\n",
    "# score = test_scores.mean().round(4)\n",
    "# train_score = train_scores.mean().round(4)\n",
    "# print(\"Mean log loss test  score using top {0} features: {1}\".format(n_feat, score))\n",
    "# print(\"Mean log loss train score using top {0} features: {1}\".format(n_feat, train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean log loss test  score: 12.2923\n",
      "Mean log loss train score: 0.0025\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='gini', class_weight='balanced')\n",
    "\n",
    "scores = cross_validate(model, X_train2, y_train, scoring='neg_log_loss', cv=5, return_train_score=True)\n",
    "# Convert negative log loss to log loss\n",
    "test_scores = -1 * scores['test_score']\n",
    "train_scores = -1 * scores['train_score']\n",
    "score = test_scores.mean().round(4)\n",
    "train_score = train_scores.mean().round(4)\n",
    "print(\"Mean log loss test  score: {0}\".format(score))\n",
    "print(\"Mean log loss train score: {0}\".format( train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may have to do a grid-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -9.03501810e-21, -6.77626358e-21, ...,\n",
       "        5.23884245e-03,  5.86846096e-03,  1.32798860e-02])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on entire dataset\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model.fit(X_train2, y_train)\n",
    "path = model.cost_complexity_pruning_path(X_train2, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "ccp_alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013279886031082988"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ccp_alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for optimal parameters\n",
    "\n",
    "Because of overfitting, we will use a relatively small number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'ccp_alpha': [1e-10, 1e-8, 1e-6, 1e-4, 1e-2, 1e-0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "clf = GridSearchCV(model, parameters, scoring='neg_log_loss', cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'ccp_alpha': [1e-10, 1e-08, 1e-06, 0.0001, 0.01, 1.0],\n",
       "                         'class_weight': [None, 'balanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0001,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'min_samples_leaf': 1,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7071378632561878"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.93096494, -11.01497057,  -8.23351146,  -6.60870272,\n",
       "        -6.48554245,  -4.47055091, -10.8981956 , -11.09059213,\n",
       "        -8.43868869,  -6.66221713,  -6.56497346,  -4.40287725,\n",
       "       -10.86231038, -11.09500554,  -8.19771318,  -6.60693549,\n",
       "        -6.32698222,  -4.49447195, -10.87787802, -11.03222916,\n",
       "        -8.43636246,  -6.63343241,  -6.51069618,  -4.50861596,\n",
       "       -10.91117473, -11.06000583,  -8.26901721,  -6.60050439,\n",
       "        -6.44929852,  -4.37457586, -10.8664666 , -11.05011638,\n",
       "        -8.42288085,  -6.57829861,  -6.58823577,  -4.43674298,\n",
       "       -10.86963002, -10.94969721,  -8.21022264,  -6.61941576,\n",
       "        -6.32649461,  -4.44401239, -10.8817089 , -11.03485412,\n",
       "        -8.46307988,  -6.66704472,  -6.50040007,  -4.52790285,\n",
       "       -10.90011216, -11.05470673,  -8.25930225,  -6.62615696,\n",
       "        -6.47050781,  -4.33358343, -10.90297845, -11.12776446,\n",
       "        -8.45078019,  -6.55836522,  -6.54996847,  -4.36474493,\n",
       "       -10.86620585, -11.12616466,  -8.22041202,  -6.58502451,\n",
       "        -6.30774085,  -4.50547423, -10.90597587, -11.06833439,\n",
       "        -8.45397689,  -6.67118045,  -6.50778802,  -4.59111838,\n",
       "        -0.70713786,  -0.72981119,  -0.70713786,  -0.71361521,\n",
       "        -0.70713786,  -0.7295097 ,  -3.9213467 ,  -1.63244166,\n",
       "        -3.69293394,  -1.62576706,  -3.31121562,  -1.3926023 ,\n",
       "        -1.65570626,  -1.12045142,  -1.6242696 ,  -1.12636101,\n",
       "        -1.57174015,  -1.11056143,  -4.86867379,  -4.14888066,\n",
       "        -4.49063745,  -3.5044153 ,  -3.98082775,  -2.81799598,\n",
       "        -0.76442994,  -0.78875263,  -0.76442994,  -0.78875263,\n",
       "        -0.76442994,  -0.78875263,  -0.72482352,  -0.78875263,\n",
       "        -0.72482352,  -0.78875263,  -0.72482352,  -0.78875263,\n",
       "        -1.02289819,  -1.09861229,  -1.02289819,  -1.09201408,\n",
       "        -1.02289819,  -1.09861229,  -0.96731094,  -1.08968783,\n",
       "        -0.96731094,  -1.09607727,  -0.96731094,  -1.07885516,\n",
       "        -0.78875263,  -0.78875263,  -0.78875263,  -0.78875263,\n",
       "        -0.78875263,  -0.78875263,  -0.78875263,  -0.78875263,\n",
       "        -0.78875263,  -0.78875263,  -0.78875263,  -0.78875263,\n",
       "        -1.09861229,  -1.09861229,  -1.09861229,  -1.09861229,\n",
       "        -1.09861229,  -1.09861229,  -1.09861229,  -1.09861229,\n",
       "        -1.09861229,  -1.09861229,  -1.09861229,  -1.09861229])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean log loss test  score using top 10000 features: 11.1994\n",
      "Mean log loss train score using top 10000 features: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# # Convert negative log loss to log loss\n",
    "# test_scores = -1 * scores['test_score']\n",
    "# train_scores = -1 * scores['train_score']\n",
    "# score = test_scores.mean().round(4)\n",
    "# train_score = train_scores.mean().round(4)\n",
    "# print(\"Mean log loss test  score using top {0} features: {1}\".format(n_feat, score))\n",
    "# print(\"Mean log loss train score using top {0} features: {1}\".format(n_feat, train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
