{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Decision tree specific modules\n",
    "from sklearn import tree\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer #Can use tfidffvectorizer as well\n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.join(os.getcwd(), os.pardir)\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_npz(os.path.join(DATA_PATH, 'training_feats.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_npz(os.path.join(DATA_PATH, 'test_feats.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49308, 35520)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 35520)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(os.path.join(BASE_PATH, '01-milestone1', 'imputed_train.json'))\n",
    "test_df =  pd.read_json(os.path.join(DATA_PATH, 'test.json.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indexes = test_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "As described in milestone 1, we will do some feature extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(train_df, min_feats=5):\n",
    "#     bathrooms = train_df['bathrooms']\n",
    "#     bedrooms = train_df['bedrooms']\n",
    "#     building_ids = train_df['building_id']\n",
    "#     latitudes = train_df['latitude']\n",
    "#     longitudes = train_df['longitude']\n",
    "#     manager_ids = train_df['manager_id']\n",
    "#     prices = train_df['price']\n",
    "    \n",
    "#     datetime = pd.to_datetime(train_df['created'])\n",
    "    \n",
    "#     months = datetime.dt.month\n",
    "#     days = datetime.dt.day\n",
    "#     hours = datetime.dt.hour\n",
    "    \n",
    "#     # Where Monday = 0, and Sunday = 6\n",
    "#     weekdays = datetime.dt.dayofweek\n",
    "    \n",
    "#     num_photos = train_df['photos'].str.len()\n",
    "    \n",
    "#     features = train_df['features'].apply(lambda x: [i.lower() for i in x])\n",
    "\n",
    "#     feature_counts = Counter()\n",
    "#     for feature in features.tolist():\n",
    "#         feature_counts.update(feature)\n",
    "#     feature = sorted([k for (k,v) in feature_counts.items() if v > min_feats])\n",
    "    \n",
    "#     key2original = defaultdict(list)\n",
    "#     k = 4\n",
    "#     for f in feature:\n",
    "#         cleaned = clean(f)\n",
    "#         key = cleaned[:k].strip()\n",
    "#         key2original[key].append(f)\n",
    "    \n",
    "#     columns = list(key2original.keys())\n",
    "    \n",
    "#     # reverse hash table\n",
    "#     original2key = {}\n",
    "#     for col in columns:\n",
    "#         for original in key2original[col]:\n",
    "#             original2key[original] = col\n",
    "            \n",
    "#     all_listing_features = {}\n",
    "\n",
    "#     for index,row in train_df.iterrows():\n",
    "#         listing_features = {}\n",
    "#         features_found = []\n",
    "#         for feature in row['features']:\n",
    "#             feature = feature.lower()\n",
    "#             if feature in original2key:\n",
    "#                 features_found.append(original2key[feature])\n",
    "#         for feature in columns:\n",
    "#                 if feature not in features_found:\n",
    "#                     listing_features[feature] = 0\n",
    "#                 else:\n",
    "#                     listing_features[feature] = 1\n",
    "#         all_listing_features[row['listing_id']] = listing_features\n",
    "\n",
    "#     one_hot_features = pd.DataFrame.from_dict(all_listing_features, orient='index')\n",
    "    \n",
    "#     # Description attribute\n",
    "    \n",
    "#     descriptions = train_df[['description']]\n",
    "#     # Removes symbols, numbers and stem the words to reduce dimentional space\n",
    "#     stemmer = PorterStemmer()\n",
    "    \n",
    "#     descriptions['description_new'] = descriptions.description.apply(lambda x: clean_description(x, stemmer))\n",
    "\n",
    "#     cvect_desc = CountVectorizer(stop_words='english', max_features=200)\n",
    "#     full_sparse = cvect_desc.fit_transform(descriptions.description_new)\n",
    "\n",
    "#     # Renaming words to avoid collisions with other feature names in the model\n",
    "#     col_desc = ['desc_'+ i for i in cvect_desc.get_feature_names()] \n",
    "#     count_vect_df = pd.DataFrame(full_sparse.todense(), columns=col_desc)\n",
    "#     descriptions = pd.concat([descriptions.reset_index(), count_vect_df],axis=1)\n",
    "    \n",
    "#     descriptions = descriptions.drop(labels=['description', 'index', 'description_new'], axis=1)\n",
    "#     descriptions.index = train_df['listing_id']\n",
    "    \n",
    "#     # The final dataframe to be returned\n",
    "#     final_train_df = pd.DataFrame()\n",
    "    \n",
    "#     final_train_df['bathrooms'] = bathrooms\n",
    "#     final_train_df['bedrooms'] = bedrooms\n",
    "#     final_train_df['building_ids'] = building_ids \n",
    "#     final_train_df['latitudes'] = latitudes\n",
    "#     final_train_df['longitudes'] = longitudes\n",
    "#     final_train_df['manager_ids'] = manager_ids\n",
    "#     final_train_df['prices'] = prices\n",
    "#     final_train_df['months'] = months\n",
    "#     final_train_df['days'] = days\n",
    "#     final_train_df['hours'] = hours\n",
    "#     final_train_df['weekdays'] = weekdays\n",
    "#     final_train_df['num_photos'] = num_photos\n",
    "#     final_train_df.index = train_df['listing_id']\n",
    "    \n",
    "#     final_train_df = final_train_df.merge(descriptions, left_index=True, right_index=True)\n",
    "#     final_train_df = final_train_df.merge(one_hot_features, left_index=True, right_index=True)\n",
    "    \n",
    "#     final_train_df = pd.concat([final_train_df, pd.get_dummies(final_train_df['building_ids'], prefix='building')], axis=1)\n",
    "#     final_train_df = pd.concat([final_train_df, pd.get_dummies(final_train_df['manager_ids'], prefix='manager')], axis=1)\n",
    "#     final_train_df = final_train_df.drop(['building_ids', 'manager_ids'], axis=1)\n",
    "\n",
    "#     return final_train_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean(s):\n",
    "#     x = s.replace(\"-\", \"\")\n",
    "#     x = x.replace(\" \", \"\")\n",
    "#     x = x.replace(\"twenty four hour\", \"24\")\n",
    "#     x = x.replace(\"24/7\", \"24\")\n",
    "#     x = x.replace(\"24hr\", \"24\")\n",
    "#     x = x.replace(\"24-hour\", \"24\")\n",
    "#     x = x.replace(\"24hour\", \"24\")\n",
    "#     x = x.replace(\"24 hour\", \"24\")\n",
    "#     x = x.replace(\"common\", \"cm\")\n",
    "#     x = x.replace(\"concierge\", \"doorman\")\n",
    "#     x = x.replace(\"bicycle\", \"bike\")\n",
    "#     x = x.replace(\"private\", \"pv\")\n",
    "#     x = x.replace(\"deco\", \"dc\")\n",
    "#     x = x.replace(\"decorative\", \"dc\")\n",
    "#     x = x.replace(\"onsite\", \"os\")\n",
    "#     x = x.replace(\"outdoor\", \"od\")\n",
    "#     x = x.replace(\"ss appliances\", \"stainless\")\n",
    "#     return x\n",
    "\n",
    "# def clean_description(x, stemmer):\n",
    "#     regex = re.compile('[^a-zA-Z ]')\n",
    "#     # For user clarity, broken it into three steps\n",
    "#     i = regex.sub(' ', x).lower()\n",
    "#     i = i.split(\" \") \n",
    "#     i= [stemmer.stem(l) for l in i]\n",
    "#     i= \" \".join([l.strip() for l in i if (len(l)>2) ]) # Keeping words that have length greater than 2\n",
    "#     return i\n",
    "\n",
    "# def feature_hash(x):\n",
    "#     cleaned = clean(x, uniq)\n",
    "#     key = cleaned[:4].strip()\n",
    "#     return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We first instantiate a decision tree model and train it naively using all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels from {low, medium high} -> {0, 1, 2}\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "We need to split the training data into a training set and a validation set (to evaluate the performance of the model).\n",
    "\n",
    "For now we do 5-fold cross_validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 36201431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial approach is to use all features for training. For the parameters, we simply use the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score:\n",
      "11.1711\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "scores = cross_validate(model, X_train, y_train, scoring='neg_log_loss', cv=5)\n",
    "# Convert negative log loss to log loss\n",
    "test_scores = -1 * scores['test_score']\n",
    "print(\"Log loss score:\")\n",
    "print(test_scores.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try training on the entire train set. We will obtain a model, train it on the test dataset, then submit to kaggle for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['high', 'low', 'medium'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the order is not correct (low corresponds to the label 1, but in the csv they expect the low to be the third column), we must swap columns for y_pred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be a \"bug\" below, I don't think I actually swapped the columns yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_csv(y_pred, X_test_indexes):\n",
    "    df = pd.DataFrame(y_pred, columns=le.classes_)\n",
    "    df.index = X_test_indexes\n",
    "    df.index.name = 'listing_id'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = create_submission_csv(y_pred, X_test_indexes)\n",
    "output.to_csv('decision_tree_predictions_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score from Kaggle\n",
    "9.18820 <- ignore, this is the old score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2\n",
    "\n",
    "It seems that using all the features is not very good. Let's use a smaller set of features.\n",
    "We can choose the top x features in order of descending mutual information (wrt the label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional things to try:\n",
    "\n",
    "- entropy for information gain\n",
    "- limiting max_depth to like 30 or so\n",
    "- class_weight = balanced\n",
    "- ccp_alpha = ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 35520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = mutual_info_classif(X_train, y_train, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean log loss test  score using top 50 features: 11.9486\n",
      "Mean log loss train score using top 50 features: 0.0013\n"
     ]
    }
   ],
   "source": [
    "n_feat = 50\n",
    "top_features = mutual_info.argsort()[-1 * n_feat:][::-1]\n",
    "\n",
    "# Only use these top n features when training, to eliminate overfitting.\n",
    "X_train_final = X_train[:,top_features]\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "scores = cross_validate(model, X_train_final, y_train, scoring='neg_log_loss', cv=5, return_train_score=True)\n",
    "# Convert negative log loss to log loss\n",
    "test_scores = -1 * scores['test_score']\n",
    "train_scores = -1 * scores['train_score']\n",
    "score = test_scores.mean().round(4)\n",
    "train_score = train_scores.mean().round(4)\n",
    "print(\"Mean log loss test  score using top {0} features: {1}\".format(n_feat, score))\n",
    "print(\"Mean log loss train score using top {0} features: {1}\".format(n_feat, train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering top 10 features.\n",
      "Mean log loss score using top 10 features: 12.1066\n",
      "Considering top 20 features.\n",
      "Mean log loss score using top 20 features: 11.4989\n",
      "Considering top 50 features.\n",
      "Mean log loss score using top 50 features: 11.9752\n",
      "Considering top 100 features.\n",
      "Mean log loss score using top 100 features: 11.7936\n",
      "Considering top 200 features.\n",
      "Mean log loss score using top 200 features: 11.7696\n",
      "Considering top 500 features.\n",
      "Mean log loss score using top 500 features: 11.65\n",
      "Considering top 1000 features.\n",
      "Mean log loss score using top 1000 features: 11.6352\n",
      "Considering top 2000 features.\n",
      "Mean log loss score using top 2000 features: 11.4958\n",
      "Considering top 5000 features.\n",
      "Mean log loss score using top 5000 features: 11.3704\n",
      "Considering top 10000 features.\n",
      "Mean log loss score using top 10000 features: 11.2833\n",
      "Considering top 35520 features.\n",
      "Mean log loss score using top 35520 features: 11.1823\n",
      "The best number of features is 35520\n",
      "The log loss for this number of features is 11.1823\n"
     ]
    }
   ],
   "source": [
    "best_score = 9999999999999999\n",
    "best_n = 0\n",
    "\n",
    "for n_feat in n_feats:\n",
    "    print(\"Considering top {0} features.\".format(n_feat))\n",
    "    top_features = mutual_info.argsort()[-1 * n_feat:][::-1]\n",
    "\n",
    "    # Only use these top n features when training, to eliminate overfitting.\n",
    "    X_train_final = X_train[:,top_features]\n",
    "    \n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    scores = cross_validate(model, X_train_final, y_train, scoring='neg_log_loss', cv=5)\n",
    "    # Convert negative log loss to log loss\n",
    "    test_scores = -1 * scores['test_score']\n",
    "    score = test_scores.mean().round(4)\n",
    "    print(\"Mean log loss score using top {0} features: {1}\".format(n_feat, score))\n",
    "    \n",
    "    \n",
    "    cross_val_scores[n_feat] = score\n",
    "    \n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_n = n_feat\n",
    "\n",
    "print(\"The best number of features is {0}\".format(best_n))\n",
    "print(\"The log loss for this number of features is {0}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on entire dataset\n",
    "X_train_final = X_test[:,best_n]\n",
    "X_test_final = X_test[:,best_n]\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test_final)\n",
    "\n",
    "output = create_submission_csv( y_pred, X_test_indexes)\n",
    "output.to_csv('decision_tree_predictions_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}