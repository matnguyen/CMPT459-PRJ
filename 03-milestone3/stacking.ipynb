{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, scale, normalize, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.join(os.getcwd(), os.pardir)\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = scipy.sparse.load_npz(os.path.join(DATA_PATH, 'training_feats_num.npz'))\n",
    "X_cat = scipy.sparse.load_npz(os.path.join(DATA_PATH, 'training_feats_cat.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(os.path.join(DATA_PATH, 'training_labels.tsv'), sep='\\t', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to numerical values\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 = medium, 1 = low, 0 = high\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scipy.sparse.load_npz(os.path.join(DATA_PATH, 'test_feats.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_index = X_num.shape[1]\n",
    "cat_index = X_cat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scipy.sparse.load_npz(os.path.join(DATA_PATH, 'training_feats.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49308x35522 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2626763 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "First let's try two different base classifiers trained on different data. One for numerical, and one for categorical. Since our results with logistic regression from milestone 2 were decent, let's try it with two logistic regression methods first. \n",
    "\n",
    "We will use a logistic regression model for the meta-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingCVClassifier, StackingClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'neg_log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000, solver='saga', penalty='none'))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(range(num_index, cat_index))),\n",
    "                      LogisticRegression(max_iter=5000, solver='saga', penalty='none'))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000, solver='saga', penalty='none'),\n",
    "                            use_probas=False,\n",
    "                            random_state=seed)\n",
    "\n",
    "prob_scores = cross_validate(sclf, X, y, scoring=metrics, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6945728921401108"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7795002488221615"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6945728889906816"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7328898688840402"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[Pipeline(memory=None,\n",
       "                                         steps=[('columnselector',\n",
       "                                                 ColumnSelector(cols=range(0, 12),\n",
       "                                                                drop_axis=False)),\n",
       "                                                ('logisticregression',\n",
       "                                                 LogisticRegression(C=1.0,\n",
       "                                                                    class_weight=None,\n",
       "                                                                    dual=False,\n",
       "                                                                    fit_intercept=True,\n",
       "                                                                    intercept_scaling=1,\n",
       "                                                                    l1_ratio=None,\n",
       "                                                                    max_iter=5000,\n",
       "                                                                    multi_class='auto',\n",
       "                                                                    n_jobs=None,\n",
       "                                                                    penalty='l2',\n",
       "                                                                    random_state=N...\n",
       "                   meta_classifier=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=100,\n",
       "                                                      multi_class='auto',\n",
       "                                                      n_jobs=None,\n",
       "                                                      penalty='none',\n",
       "                                                      random_state=None,\n",
       "                                                      solver='saga', tol=0.0001,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=True, verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_sclf = StackingClassifier(classifiers=[pipe1, pipe2], \n",
    "                                meta_classifier=LogisticRegression(solver='saga', penalty='none'),\n",
    "                                use_probas=True)\n",
    "\n",
    "naive_sclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try using probabilities as the meta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000, solver='saga', penalty='none'))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(range(num_index, cat_index))),\n",
    "                      LogisticRegression(max_iter=5000, solver='saga', penalty='none'))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000, solver='saga', penalty='l1'),\n",
    "                            use_probas=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "prob_scores = cross_validate(sclf, X, y, scoring=metrics, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7153402606512413"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6615378082036653"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8170732890192512"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4941857597255641"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try adding l1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/matthew/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(solver='saga', penalty='l1'))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(range(num_index, cat_index))),\n",
    "                      LogisticRegression(solver='saga', penalty='l1'))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(solver='saga', penalty='l1'),\n",
    "                            use_probas=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "prob_scores = cross_validate(sclf, X, y, scoring=metrics, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7198628570469621"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6434958057546839"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746151738012778"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5921988670667642"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try adding l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(range(num_index, cat_index))),\n",
    "                      LogisticRegression(max_iter=5000))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000), \n",
    "                            random_state=seed)\n",
    "\n",
    "scores = cross_validate(sclf, X, y, scoring=metrics, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.697026841829888"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7665314960724455"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8170732890192512"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4941857597255641"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually better than our baseline logistic regression model, so perhaps we can improve further on this with some optimizations. Now let's see if we get better results for using probabilities in the meta classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(range(num_index, cat_index))),\n",
    "                      LogisticRegression(max_iter=5000))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000),\n",
    "                            use_probas=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "prob_scores = cross_validate(sclf, X, y, scoring=metrics, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7254806462022477"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6229847874937653"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132047437638462"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47514005804015386"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modifications\n",
    "First let's try doing feature selection on the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(mutual_info_classif, k=1000).fit(X_cat, y)\n",
    "X_cat_new = kbest.transform(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = kbest.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = np.nonzero(support)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_support = [x + num_index for x in support]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try training the l2 logistic regression model the feature selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(new_support)),\n",
    "                      LogisticRegression(max_iter=5000))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000),\n",
    "                            use_probas=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "prob_scores = cross_validate(sclf, X, y, scoring=metrics, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7268597590877421"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6257758349640075"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7380648191100505"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6065777936441414"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log loss has gone down again, now let's try standardizing all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = RobustScaler(with_centering=False)\n",
    "X_new_normalized = enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(new_support)),\n",
    "                      LogisticRegression(max_iter=5000))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000),\n",
    "                            use_probas=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "prob_scores = cross_validate(sclf, X_new_normalized, y, scoring=metrics, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7269611645679446"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6254488292172622"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7378062412287074"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6062556736728788"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log loss goes down slightly. Now we performed grid search to find optimal parameters\n",
    "\n",
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was run on a compute cluster \n",
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000, solver='saga'))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(new_support)),\n",
    "                      LogisticRegression(max_iter=5000, solver='saga'))\n",
    "\n",
    "params = {'pipeline-1__logisticregression__C': [1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "          'pipeline-1__logisticregression__penalty': ['l1', 'l2'],\n",
    "          'pipeline-2__logisticregression__C': [1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "          'pipeline-2__logisticregression__penalty': ['l1', 'l2'],\n",
    "          'meta_classifier__C': [1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "          'meta_classifier__penalty': ['l1', 'l2']}\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000, solver='saga'),\n",
    "                            use_probas=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "grid = GridSearchCV(sclf, params, cv=5, verbose=2, refit='neg_log_loss', scoring=metrics, n_jobs=-1)\n",
    "grid.fit(X_new_normalized, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the best parameters to be:\n",
    "\n",
    "Numerical model: C = 100, l1\n",
    "\n",
    "Categorical model: C = 10, l2\n",
    "\n",
    "Meta classifier: C = 100, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000, C=100, solver='saga', penalty='l1'))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(new_support)),\n",
    "                      LogisticRegression(max_iter=5000, C=10, penalty='l2'))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000, C=100, solver='saga', penalty='l1'),\n",
    "                            use_probas=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "prob_scores = cross_validate(sclf, X_new_normalized, y, scoring=metrics, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7259877126781384"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6261126349101211"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['test_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7374310493847532"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6070221036728812"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores['train_neg_log_loss'].mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[Pipeline(memory=None,\n",
       "                                         steps=[('columnselector',\n",
       "                                                 ColumnSelector(cols=range(0, 12),\n",
       "                                                                drop_axis=False)),\n",
       "                                                ('logisticregression',\n",
       "                                                 LogisticRegression(C=10,\n",
       "                                                                    class_weight=None,\n",
       "                                                                    dual=False,\n",
       "                                                                    fit_intercept=True,\n",
       "                                                                    intercept_scaling=1,\n",
       "                                                                    l1_ratio=None,\n",
       "                                                                    max_iter=5000,\n",
       "                                                                    multi_class='auto',\n",
       "                                                                    n_jobs=None,\n",
       "                                                                    penalty='l2',\n",
       "                                                                    random_state=No...\n",
       "                   meta_classifier=LogisticRegression(C=100, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=5000,\n",
       "                                                      multi_class='auto',\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      random_state=None,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=True, verbose=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1 = make_pipeline(ColumnSelector(cols=(range(0, num_index))),\n",
    "                      LogisticRegression(max_iter=5000, C=100, solver='saga', penalty='l1'))\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(new_support)),\n",
    "                      LogisticRegression(max_iter=5000, C=10, penalty='l2'))\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=LogisticRegression(max_iter=5000, C=100, solver='saga', penalty='l1'),\n",
    "                            use_probas=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "opt_sclf.fit(X_new_normalized, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of test data\n",
    "Let's first generate the test results for our unoptimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_unopt = naive_sclf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05372743, 0.6882577 , 0.25801487],\n",
       "       [0.01973129, 0.89014241, 0.0901263 ],\n",
       "       [0.01782019, 0.86816979, 0.11401003],\n",
       "       ...,\n",
       "       [0.03007987, 0.79178372, 0.17813641],\n",
       "       [0.46199034, 0.14522478, 0.39278488],\n",
       "       [0.0357455 , 0.79116652, 0.17308798]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_unopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05372743, 0.01973129, 0.01782019, ..., 0.03007987, 0.46199034,\n",
       "       0.0357455 ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_unopt[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(os.path.join(DATA_PATH, 'test_ids.tsv'), sep='\\t', header=None, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_unopt = pd.DataFrame({'listing_id': test_ids[0].values, 'high': scores_unopt[:,0], 'medium': scores_unopt[:,2], \n",
    "                               'low': scores_unopt[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_unopt.to_csv('stacking_unopt_test_out.tsv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate it for the optimized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new_normalized = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_opt = opt_sclf.predict_proba(X_test_new_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05661287, 0.67820566, 0.26518147],\n",
       "       [0.02674066, 0.86736963, 0.10588971],\n",
       "       [0.0303675 , 0.81779823, 0.15183427],\n",
       "       ...,\n",
       "       [0.03199778, 0.78380622, 0.184196  ],\n",
       "       [0.39368618, 0.16587651, 0.44043731],\n",
       "       [0.04342653, 0.76499966, 0.1915738 ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_opt = pd.DataFrame({'listing_id': test_ids[0].values, 'high': scores_opt[:,0], 'medium': scores_opt[:,2], \n",
    "                             'low': scores_opt[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_opt.to_csv('stack_opt_test_out.tsv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
